<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <title>OpenAI Realtime (WebRTC) - Toggle & Transcript & Save</title>
  <style>
    :root { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }
    * { box-sizing: border-box; }
    body { margin: 0; display: grid; grid-template-columns: 1fr 420px; grid-template-rows: auto 1fr; height: 100vh; }
    header { grid-column: 1 / -1; padding: 10px 16px; background: #111827; color: #e5e7eb; display: flex; gap: 12px; align-items: center; }
    main { padding: 16px; overflow: auto; }
    aside { border-left: 1px solid #e5e7eb; display: grid; grid-template-rows: auto 1fr auto; min-width: 320px; }
    .controls { display: flex; gap: 8px; align-items: center; }
    button { padding: 8px 14px; font-size: 14px; cursor: pointer; border: 1px solid #ddd; border-radius: 8px; background: #fff; }
    button:disabled { opacity: .6; cursor: not-allowed; }
    .status { margin-left: auto; opacity: .9; font-size: 14px; }
    .panel-title { padding: 10px 12px; font-weight: 600; border-bottom: 1px solid #eee; background: #f8fafc; }
    .log-wrap { position: relative; }
    .log { overflow: auto; padding: 12px; background: #fafafa; border-top: 1px solid #eee; border-bottom: 1px solid #eee; height: 100%; }
    .msg { margin: 10px 0; border-radius: 8px; padding: 8px 10px; background: #fff; border: 1px solid #eee; }
    .role { font-weight: 700; font-size: 12px; opacity: .75; margin-bottom: 4px; }
    .user .role { color: #2563eb; }
    .assistant .role { color: #059669; }
    .event .role { color: #6b7280; }
    .text { white-space: pre-wrap; word-break: break-word; }
    .footer { padding: 10px; display: flex; gap: 8px; justify-content: space-between; align-items: center; }
    .hint { font-size: 12px; color: #6b7280; }

    /* Avatar: å·¦ã‚µã‚¤ãƒ‰ã«å¤§ããå¸¸æ™‚è¡¨ç¤ºï¼ˆåœæ­¢ã¯pauseï¼‰ */
    .avatar-wrap {
      position: fixed; left: 16px; top: 50%; transform: translateY(-50%);
      width: 360px; height: 360px;
      border-radius: 9999px; overflow: hidden; border: 2px solid #e5e7eb; background: #000; z-index: 20;
      box-shadow: 0 10px 30px rgba(0,0,0,.25);
      pointer-events: none; /* UIæ“ä½œã®é‚ªé­”ã‚’ã—ãªã„ */
    }
    .avatar-wrap video { width: 100%; height: 100%; object-fit: cover; }
    .avatar-wrap.speaking { animation: avatarPulse 1.4s infinite; }
    @keyframes avatarPulse {
      0% { box-shadow: 0 0 0 0 rgba(99,102,241,.6); }
      70% { box-shadow: 0 0 0 28px rgba(99,102,241,0); }
      100% { box-shadow: 0 0 0 0 rgba(99,102,241,0); }
    }
    @media (max-width: 1200px) {
      .avatar-wrap { width: 260px; height: 260px; }
    }
  </style>
</head>
<body>
  <header>
    <div class="controls">
      <button id="toggle">â–¶ Start</button>
      <button id="clear" title="ãƒ­ã‚°ã‚’æ¶ˆå»">ğŸ§¹ Clear</button>
      <button id="export" title="JSONã§ä¿å­˜">ğŸ’¾ Export JSON</button>
    </div>
    <div class="status" id="status">Idle</div>
  </header>

  <main>
    <h2>Realtime Voice Demo</h2>
    <p>
      ã€Œâ–¶ Startã€ã§ä¼šè©±é–‹å§‹ï¼ã€Œâ–  Stopã€ã§åœæ­¢ã€‚<br/>
      å³å´ã«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®è¿”ç­”ãŒ <b>å­—å¹•ã¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º</b> ã•ã‚Œã€ç¢ºå®šå¾Œã¯ãƒ­ã‚°ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
    </p>
    <ul>
      <li>ãƒ­ã‚°ã¯ <code>localStorage</code> ã«è‡ªå‹•ä¿å­˜ï¼ˆãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚‚æ®‹ã‚Šã¾ã™ï¼‰</li>
      <li>ã€ŒExport JSONã€ã§ä¼šè©±å±¥æ­´ã‚’æ›¸ãå‡ºã—</li>
      <li>ãƒ¦ãƒ¼ã‚¶ãƒ¼å­—å¹•ã¯ç¾æ™‚ç‚¹ã§ã¯ã‚ªãƒ•ï¼ˆå¾Œã‹ã‚‰è¿½åŠ å¯èƒ½ï¼‰</li>
    </ul>
  </main>

  <aside>
    <div class="panel-title">Transcript / Logs</div>

    <div class="log-wrap">
      <div class="log" id="log"></div>

      <!-- ãƒ©ã‚¤ãƒ–å­—å¹•ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ -->
      <div class="msg user" id="live-user" style="padding:12px; display:none; position: sticky; bottom: 48px; margin:0; border-bottom-left-radius:0; border-bottom-right-radius:0; border-color:#bfdbfe; background:#eff6ff;">
        <div class="role">USER <small>speaking...</small></div>
        <div class="text" id="live-user-text"></div>
      </div>

      <!-- ãƒ©ã‚¤ãƒ–å­—å¹•ï¼ˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼‰ -->
      <div class="msg assistant" id="live-assistant" style="padding:12px; display:none; position: sticky; bottom: 0; margin:0; border-top-left-radius: 0; border-top-right-radius:0; border-color:#d1fae5; background:#ecfdf5;">
        <div class="role">ASSISTANT <small>typing...</small></div>
        <div class="text" id="live-assistant-text"></div>
      </div>
    </div>

    <div class="footer">
      <small class="hint">Autosave: localStorage</small>
      <small id="ice" class="hint"></small>
    </div>
  </aside>

  <!-- Assistant Avatar: å·¦ã«å¸¸æ™‚è¡¨ç¤ºï¼ˆåœæ­¢ã¯pauseï¼‰ -->
  <div id="avatar" class="avatar-wrap" title="Assistant Avatar" aria-hidden="true">
    <video id="avatarVideo" preload="auto" playsinline loop muted poster="avatar-poster.jpg">
      <source src="avatar-talking.mp4" type="video/mp4" />
    </video>
  </div>

  <script>
    // ========= DOM =========
    const btn = document.getElementById("toggle");
    const btnClear = document.getElementById("clear");
    const btnExport = document.getElementById("export");
    const statusEl = document.getElementById("status");
    const iceEl = document.getElementById("ice");
    const logEl = document.getElementById("log");
    const liveRow = document.getElementById("live-assistant");
    const liveTextEl = document.getElementById("live-assistant-text");
    const liveUserRow = document.getElementById("live-user");
    const liveUserTextEl = document.getElementById("live-user-text");
    // ã‚¢ãƒã‚¿ãƒ¼
    const avatarEl = document.getElementById("avatar");
    const avatarVideoEl = document.getElementById("avatarVideo");

    // ========= ä¼šè©±ãƒ­ã‚°ï¼ˆlocalStorageé€£æºï¼‰ =========
    let conversation = [];
    function nowIso() { return new Date().toISOString(); }
    function escapeHtml(s) { return s.replace(/[&<>"']/g, c => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[c])); }
    function saveLocal() { try { localStorage.setItem("realtime_conversation", JSON.stringify(conversation)); } catch {} }
    function loadLocal() { try { const raw = localStorage.getItem("realtime_conversation"); if (raw) { conversation = JSON.parse(raw); renderLog(); } } catch {} }
    function clearLog() { conversation = []; saveLocal(); renderLog(); }
    function addMessage(role, text) { if (!text) return; conversation.push({ role, text, ts: nowIso() }); renderLog(); saveLocal(); }
    function renderLog() {
      logEl.innerHTML = "";
      for (const m of conversation) {
        const div = document.createElement("div");
        div.className = `msg ${m.role}`;
        div.innerHTML = `<div class="role">${m.role.toUpperCase()} <small>${m.ts}</small></div><div class="text">${escapeHtml(m.text)}</div>`;
        logEl.appendChild(div);
      }
      logEl.scrollTop = logEl.scrollHeight;
    }
    loadLocal();

    // ========= Avatar Controlï¼ˆVADã§åˆ¶å¾¡ï¼šéŸ³ãŒå‡ºã¦ã„ã‚‹é–“ã¯å†ç”Ÿï¼‰ =========
    let speakStopTimer = null;
    function startAvatarSpeaking() {
      if (speakStopTimer) { clearTimeout(speakStopTimer); speakStopTimer = null; }
      avatarEl.classList.add("speaking");
      try {
        if (avatarVideoEl.paused) {
          avatarVideoEl.currentTime = 0;
          avatarVideoEl.play();
        }
      } catch (e) { console.warn("avatar play blocked:", e?.name || e); }
    }
    function stopAvatarSpeaking(immediate = false) {
      const stop = () => {
        avatarEl.classList.remove("speaking");
        try { avatarVideoEl.pause(); } catch {}
      };
      if (immediate) return stop();
      if (speakStopTimer) clearTimeout(speakStopTimer);
      speakStopTimer = setTimeout(stop, 700); // ä½™éŸ»
    }

    // ====== Web Audio VADï¼ˆéŸ³å£°ã‚¨ãƒãƒ«ã‚®ãƒ¼ç›£è¦–ï¼‰ ======
    let audioCtx = null, analyser = null, vadSrc = null, vadInterval = null, lastVoiceMs = 0;
    const VAD = { threshold: 0.018, hangoverMs: 900, intervalMs: 66 }; // ç›®å®‰: 0.015ã€œ0.03

    function setupAssistantVAD(stream) {
      try {
        if (!audioCtx) {
          const AC = window.AudioContext || window.webkitAudioContext;
          audioCtx = new AC();
        }
        audioCtx.resume?.();

        if (vadSrc) { try { vadSrc.disconnect(); } catch {} vadSrc = null; }
        if (!analyser) {
          analyser = audioCtx.createAnalyser();
          analyser.fftSize = 2048;
          analyser.smoothingTimeConstant = 0.08;
        }
        vadSrc = audioCtx.createMediaStreamSource(stream);
        vadSrc.connect(analyser);

        const data = new Uint8Array(analyser.fftSize);
        lastVoiceMs = performance.now();
        if (vadInterval) { clearInterval(vadInterval); vadInterval = null; }

        vadInterval = setInterval(() => {
          analyser.getByteTimeDomainData(data);
          // å¹³å‡çµ¶å¯¾åå·®ã§ãƒ¬ãƒ™ãƒ«æ¨å®šï¼ˆ0..1ï¼‰
          let sum = 0;
          for (let i = 0; i < data.length; i++) {
            const v = (data[i] - 128) / 128;
            sum += Math.abs(v);
          }
          const level = sum / data.length; // å°ã•ã‘ã‚Œã°ç„¡éŸ³ã«è¿‘ã„
          const now = performance.now();

          if (level > VAD.threshold) {
            lastVoiceMs = now;
            startAvatarSpeaking(); // éŸ³ãŒå‡ºã¦ã„ã‚‹é™ã‚Šå†ç”Ÿç¶­æŒ
          } else if (now - lastVoiceMs > VAD.hangoverMs) {
            stopAvatarSpeaking(true); // ä¸€å®šæ™‚é–“ç„¡éŸ³ã§åœæ­¢
          }
        }, VAD.intervalMs);
      } catch (err) {
        console.warn("VAD setup failed:", err?.message || err);
      }
    }

    function teardownVAD() {
      if (vadInterval) { clearInterval(vadInterval); vadInterval = null; }
      if (vadSrc) { try { vadSrc.disconnect(); } catch {} vadSrc = null; }
      // analyser / audioCtx ã¯å†åˆ©ç”¨å¯ã€‚é–‰ã˜ãŸã„å ´åˆã¯ä»¥ä¸‹ã‚’æœ‰åŠ¹åŒ–ã€‚
      // try { audioCtx?.close(); } catch {}
    }

    // ========= æ¥ç¶šåˆ¶å¾¡ =========
    let pc = null, dc = null, micStream = null, remoteAudio = null;
    let running = false, cleaning = false;

    let currentAssistantText = "";
    let currentUserText = "";

    function setStatus(t) { statusEl.textContent = t; }
    function setRunningState(on) {
      running = on;
      btn.textContent = on ? "â–  Stop" : "â–¶ Start";
      setStatus(on ? "Connected" : "Idle");
      if (!on) { iceEl.textContent = ""; }
    }

    async function fetchEphemeralSession() {
      const r = await fetch("/token", { method: "POST" });
      if (!r.ok) throw new Error(await r.text());
      return r.json();
    }

    async function startSession() {
      if (running) return;
      setStatus("Starting...");
      btn.disabled = true;
      try {
        // 1) ãƒã‚¤ã‚¯ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œå†…ã§AudioContextã‚’èµ·ã“ã›ã‚‹ï¼‰
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // AudioContextã¯æ—©ã‚ã«èµ·å‹•ï¼ˆiOSå¯¾ç­–ï¼‰
        if (!audioCtx) {
          const AC = window.AudioContext || window.webkitAudioContext;
          audioCtx = new AC();
          await audioCtx.resume();
        }

        // 2) Ephemeral token
        const session = await fetchEphemeralSession();

        // 3) PeerConnection
        pc = new RTCPeerConnection();
        micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

        // 4) å—ä¿¡éŸ³å£°
        pc.ontrack = (e) => {
          if (remoteAudio) { try { remoteAudio.pause(); } catch {}; try { remoteAudio.remove(); } catch {} }
          remoteAudio = document.createElement("audio");
          remoteAudio.autoplay = true;
          remoteAudio.srcObject = e.streams[0];
          // å—ä¿¡ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¤ãƒ™ãƒ³ãƒˆï¼ˆè£œå¼·ï¼‰
          remoteAudio.addEventListener("play", () => startAvatarSpeaking());
          remoteAudio.addEventListener("pause", () => stopAvatarSpeaking(true));
          remoteAudio.addEventListener("ended", () => stopAvatarSpeaking(true));
          document.body.appendChild(remoteAudio);

          // â˜… AssistantéŸ³å£°ã®VADã‚’é–‹å§‹
          setupAssistantVAD(e.streams[0]);
        };

        // 5) DataChannel
        const attachDataChannel = (channel) => {
          dc = channel;
          dc.onopen = () => {
            addMessage("event", "Session started");
            dc.send(JSON.stringify({
              type: "response.create",
              response: {
                instructions: "ã‚ãªãŸã¯è¦ªåˆ‡ãªéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€‚ç°¡æ½”ãªæ—¥æœ¬èªã§è¦ç‚¹ã‚’è¿”ç­”ã—ã¦ãã ã•ã„ã€‚",
                modalities: ["text", "audio"]
              }
            }));
            dc.send(JSON.stringify({
              type: "response.create",
              response: {
                input_text: "ãƒ†ã‚¹ãƒˆã§ã™ã€‚çŸ­ãè‡ªå·±ç´¹ä»‹ã—ã¦ã¿ã¦ãã ã•ã„ã€‚",
                modalities: ["text", "audio"]
              }
            }));
          };

          let debugCount = 0;
          const DEBUG_LIMIT = 10;

          dc.onmessage = (ev) => {
            try {
              const e = JSON.parse(ev.data);
              if (debugCount < DEBUG_LIMIT) { console.log("[Realtime event]", e); debugCount++; }

              // ===== ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆå¢—åˆ†ï¼ˆé–‹å§‹ãƒˆãƒªã‚¬ã®ã¿åˆ©ç”¨ï¼‰=====
              let deltaText = "";
              if (e.type === "response.delta" && typeof e.delta === "string") deltaText = e.delta;
              if (e.type === "response.text.delta" && typeof e.delta === "string") deltaText = e.delta;
              if (e.type === "response.output_text.delta" && typeof e.delta === "string") deltaText = e.delta;
              if (e.type === "response.audio_transcript.delta" && typeof e.delta === "string") deltaText = e.delta;
              if (!deltaText && e?.delta?.text) deltaText = e.delta.text;

              if (deltaText) {
                currentAssistantText += deltaText;
                // é–‹å§‹ã¯ç©æ¥µçš„ã«ï¼ˆVADã¨äºŒé‡ã§ã‚‚OKï¼‰
                startAvatarSpeaking();
              }

              // ===== ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ï¼ˆdeltaï¼‰=====
              let userDelta = "";
              if (e.type === "conversation.item.input_audio_transcription.delta" && typeof e.delta === "string") userDelta = e.delta;
              if (!userDelta && e.type === "input_audio_buffer.transcript.delta" && typeof e.delta === "string") userDelta = e.delta;

              if (userDelta) {
                currentUserText += userDelta;
                liveUserRow.style.display = "block";
                liveUserTextEl.textContent = currentUserText;
                logEl.scrollTop = logEl.scrollHeight;
              }

              // ===== å¿œç­”å®Œäº† =====
              const isDone =
                e.type === "response.completed" ||
                e.type === "response.text.done" ||
                e.type === "response.output_text.done" ||
                e.type === "response.audio_transcript.done";

              if (isDone) {
                const text = currentAssistantText.trim();
                if (text) addMessage("assistant", text);
                currentAssistantText = "";
                liveTextEl.textContent = "";
                liveRow.style.display = "none";
                // â˜… ã“ã“ã§ stop ã¯ã—ãªã„ â†’ VADï¼ˆå®Ÿéš›ã®ç„¡éŸ³ï¼‰ã§æ­¢ã‚ã‚‹
                // stopAvatarSpeaking();  // â† ç„¡åŠ¹åŒ–
              }

              // å…¬å¼ï¼šresponse.done ã‚‚åŒæ§˜
              if (e.type === "response.done") {
                const text = currentAssistantText.trim();
                if (text) addMessage("assistant", text);
                currentAssistantText = "";
                liveTextEl.textContent = "";
                liveRow.style.display = "none";
                // stopAvatarSpeaking(); // â† ç„¡åŠ¹åŒ–
              }

              // ===== ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã®å®Œäº† =====
              const userDone =
                e.type === "conversation.item.input_audio_transcription.completed" ||
                e.type === "input_audio_buffer.transcript.completed" ||
                e.type === "input_audio_buffer.transcript.done";

              if (userDone) {
                const finalUserText = (e?.transcript?.text || currentUserText || "").trim();
                if (finalUserText) addMessage("user", finalUserText);
                currentUserText = "";
                liveUserTextEl.textContent = "";
                liveUserRow.style.display = "none";
              }
            } catch { /* éJSONã¯ç„¡è¦– */ }
          };
        };

        attachDataChannel(pc.createDataChannel("oai-events"));
        pc.ondatachannel = (ev) => { if (!dc || dc.readyState === "closed") attachDataChannel(ev.channel); };

        pc.oniceconnectionstatechange = () => {
          const s = pc.iceConnectionState;
          iceEl.textContent = `ICE: ${s}`;
        };

        // 6) SDPäº¤æ›
        const offer = await pc.createOffer({ offerToReceiveAudio: true });
        await pc.setLocalDescription(offer);

        const sdpUrl = "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview";
        const resp = await fetch(sdpUrl, {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${session.client_secret.value}`,
            "Content-Type": "application/sdp",
            "OpenAI-Beta": "realtime=v1"
          },
          body: offer.sdp
        });
        const answerSdp = await resp.text();
        await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

        setRunningState(true);
      } catch (err) {
        console.error(err);
        setStatus("Failed to start: " + (err?.message || err));
        await stopSession(true);
      } finally {
        btn.disabled = false;
      }
    }

    async function stopSession(silent = false) {
      if (cleaning) return;
      cleaning = true;
      try {
        try { if (dc && dc.readyState !== "closed") dc.close(); } catch {}
        dc = null;

        if (pc) {
          try { pc.getSenders().forEach(s => { try { s.track.stop(); } catch {} }); } catch {}
          try { pc.close(); } catch {}
        }
        pc = null;

        if (micStream) {
          try { micStream.getTracks().forEach(t => t.stop()); } catch {}
        }
        micStream = null;

        if (remoteAudio) {
          try { remoteAudio.pause(); } catch {}
          try { remoteAudio.srcObject = null; } catch {}
          try { remoteAudio.remove(); } catch {}
        }
        remoteAudio = null;

        // ãƒ©ã‚¤ãƒ–è¡Œãƒªã‚»ãƒƒãƒˆ
        currentAssistantText = "";
        liveTextEl.textContent = "";
        liveRow.style.display = "none";
        liveUserTextEl.textContent = "";
        liveUserRow.style.display = "none";

        // VADåœæ­¢ & ã‚¢ãƒã‚¿ãƒ¼åœæ­¢
        teardownVAD();
        stopAvatarSpeaking(true);

        if (!silent) addMessage("event", "Session stopped");
      } finally {
        setRunningState(false);
        cleaning = false;
      }
    }

    // ========= UIã‚¤ãƒ™ãƒ³ãƒˆ =========
    btn.addEventListener("click", async () => {
      if (running) { btn.disabled = true; await stopSession(); btn.disabled = false; }
      else { await startSession(); }
    });
    btnClear.addEventListener("click", () => { if (confirm("ãƒ­ã‚°ã‚’æ¶ˆå»ã—ã¾ã™ã‹ï¼Ÿ")) clearLog(); });
    btnExport.addEventListener("click", () => {
      const blob = new Blob([JSON.stringify({ conversation }, null, 2)], { type: "application/json" });
      const a = document.createElement("a");
      const ts = new Date().toISOString().replace(/[:.]/g, "");
      a.href = URL.createObjectURL(blob);
      a.download = `conversation-${ts}.json`;
      a.click();
      URL.revokeObjectURL(a.href);
    });
    window.addEventListener("beforeunload", () => {
      try { stopAvatarSpeaking(true); } catch {}
      try { teardownVAD(); } catch {}
    });
  </script>
</body>
</html>
